---
title: "Assessment 3: Group Project"
team: "Team Echo"
session: "Hexa 2, 2024"
coursecode: "ZZSC9020"
authors:
  - "Chuang, Keith – z5449930"
  - "Gandhi, Rupesh – z5368767"
  - "Melbin, Joseph – z5394849"
  - "CHIU, Yiu Tong – z5039191"
date: "2024-04-20"

Acknowledgements: 
  - "TBC."
  - "TBC."
  - "TBC."
  - "TBC."

output: html_document

---

# Abstract

---

# Contents

---

# 1.0 Introduction

---

# 2.0 Literature Review

## 2.1 Industry/Operational Context

### 2.1.1 Variables of Interest
#### 2.1.1.1 Temperature
#### 2.1.1.2 Population
#### 2.1.1.3 Industry Base
#### 2.1.1.4 Renewable Engery Prevalence

## 2.2 Research Topic

## 2.3 Statistical Models

### 2.3.1 Regression Analysis

#### 2.3.1.1 Linear Models 

#### 2.3.1.2 Generalised Models

#### 2.3.1.3 Logistics Models

#### 2.3.1.4 Poisson Models

#### 2.3.1.5 Log-Linear Models

#### 2.3.1.6 Model Assessment

#### 2.3.1.7 Polynomial Models

#### 2.3.1.8 Splines

#### 2.3.1.9 Generalised Additive Models

### 2.3.2 Multivariate Analysis

---

# 3.0 Material and Methods

# Packages

```{r}

install.packages("readr")
install.packages("here")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("lubridate")
install.packages("mgcv")

```



```{r}

library(readr)
library(here)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(mgcv)
library(fpp2)
library(fable)
library(feasts)

```

---

# 4.0 Exploratory Data Analysis

## 4.1 Area of Research
Determine the efficacy of temperature as the independent variable in prediction 
of energy demand in the subsequent 24 hours on a half hourly basis for NSW 
utilizing statistical models i.e. regression. Explore the predictive improvement 
through the addition of independent variables. Do these models provide 
comparable predictive results to the supplied predictions and if so under what 
circumstances.

## 4.2 Collecting and Loading Data

### 4.2.1 Provided Data 

``` {r}

# Load Data

# Adjusting the paths according to the Github structure:

# VIC
data_forecastdemand_vic <- read_csv(unzip("../data/Australia/a.zip", files = "a/forecastdemand_vic.csv", exdir = tempdir())[1])
data_temperature_vic <- read_csv(unzip("../data/Australia/d.zip", files = "d/temprature_vic.csv", exdir = tempdir())[1])
data_demand_vic <- read_csv(unzip("../data/Australia/d.zip", files = "d/totaldemand_vic.csv", exdir = tempdir())[1])

# SA
data_forecastdemand_sa <- read_csv(unzip("../data/Australia/b.zip", files = "b/forecastdemand_sa.csv", exdir = tempdir())[1])
data_temperature_sa <- read_csv(unzip("../data/Australia/d.zip", files = "d/temprature_sa.csv", exdir = tempdir())[1])
data_demand_sa <- read_csv(unzip("../data/Australia/d.zip", files = "d/totaldemand_sa.csv", exdir = tempdir())[1])

# QLD
data_forecastdemand_qld <- read_csv(unzip("../data/Australia/c.zip", files = "c/forecastdemand_qld.csv", exdir = tempdir())[1])
data_temperature_qld <- read_csv(unzip("../data/Australia/d.zip", files = "d/temprature_qld.csv", exdir = tempdir())[1])
data_demand_qld <- read_csv(unzip("../data/Australia/d.zip", files = "d/totaldemand_qld.csv", exdir = tempdir())[1])



# NSW
#data_forecastdemand_nsw <- read_csv(here("/Users/josephrobertmelbin/Documents/GitHub/Project2/data/NSW/forecastdemand_nsw.csv"))
data_temperature_nsw <- read_csv(unzip("../data/NSW/temperature_nsw.csv.zip", files = "temperature_nsw.csv", exdir = tempdir())[1])
data_demand_nsw <- read_csv(unzip("../data/NSW/totaldemand_nsw.csv.zip", files = "totaldemand_nsw.csv", exdir = tempdir())[1])


```

### 4.2.2 Sourced Data



## 4.3.1 Initial Data Inspection

``` {r}
# Generate Some Useful Functions

# check for null values
check_for_na <- function(data) {
  for (col_index in seq_along(data)) {
    has_na <- any(is.na(data[[col_index]]))
    cat("Column", col_index, "has NA values:", has_na, "\n")
  }
}

# check for unique values
#check_unique_entries <- function(data) {
#  unique_entries_list <- list()
#  for (col_name in names(data)) {
#    unique_entries <- unique(data[[col_name]])
#    unique_entries_list[[col_name]] <- unique_entries
#  }
#  return(unique_entries_list)
#}

```

``` {r}
# VIC
# check structure
str(data_forecastdemand_vic)
str(data_temperature_vic)
str(data_demand_vic)

# check for null values
check_for_na(data_forecastdemand_vic)
check_for_na(data_temperature_vic)
check_for_na(data_demand_vic)

# check character data types for uniqueness
unique(data_forecastdemand_vic$REGIONID)
unique(data_temperature_vic$LOCATION)
unique(data_demand_vic$REGIONID) # ensure REGIONID matches
```

``` {r}
# SA
# check structure
str(data_forecastdemand_sa)
str(data_temperature_sa)
str(data_demand_sa)

# check for null values
check_for_na(data_forecastdemand_sa)
check_for_na(data_temperature_sa)
check_for_na(data_demand_sa)

# check character data types for uniqueness
unique(data_forecastdemand_sa$REGIONID)
unique(data_temperature_sa$LOCATION)
unique(data_demand_sa$REGIONID) # ensure REGIONID matches
```

``` {r}
# QLD
# check structure
str(data_forecastdemand_qld)
str(data_temperature_qld)
str(data_demand_qld)

# check for null values
check_for_na(data_forecastdemand_qld)
check_for_na(data_temperature_qld)
check_for_na(data_demand_qld)

# check character data types for uniqueness
unique(data_forecastdemand_qld$REGIONID)
unique(data_temperature_qld$LOCATION)
unique(data_demand_qld$REGIONID) # ensure REGIONID matches
```

``` {r}
# NSW
# check structure
str(data_forecastdemand_nsw)
str(data_temperature_nsw)
str(data_demand_nsw)

# check for null values
check_for_na(data_forecastdemand_nsw)
check_for_na(data_temperature_nsw)
check_for_na(data_demand_nsw)

# check character data types for uniqueness
unique(data_forecastdemand_nsw$REGIONID)
unique(data_temperature_nsw$LOCATION)
unique(data_demand_nsw$REGIONID) # ensure REGIONID matches
```

## 4.3.2 Initial data wrangling

```{r}
# Converts string DATETIME into dttm and creates timestamp columns
wrangle_demand_data <- function(df) {
  if ("DATETIME" %in% names(df)) {
    df <- df %>%
      mutate(DATETIME = dmy_hm(`DATETIME`, tz='AUstralia/Brisbane'),
                          Year = year(DATETIME),        # Extract year
                          Month = month(DATETIME),      # Extract month
                          Day = day(DATETIME),          # Extract day
                          Hour = hour(DATETIME),        # Extract hour
                          Minute = minute(DATETIME)) %>%  # Extract minute
      mutate(TimeOfDay = Hour + Minute / 60,   # Time of the day (0 - 24)
             WeekOfMonth = factor(week(DATETIME) - week(floor_date(DATETIME, "month")) + 1, levels = c(1,2,3,4,5,6)),
             DayOfWeek = factor(wday(DATETIME, label=TRUE), levels = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")))
  } else {
    warning("DATETIME column not found in the dataframe.")
  }
  
  return(df)
}
```

```{r}


df_demand_nsw <- wrangle_demand_data(data_demand_nsw)
df_temperature_nsw <- wrangle_demand_data(data_temperature_nsw)


```



## 4.4 Summary Statistics

``` {r}
# detect outliers, based on z score
detect_outliers <- function(data) {
  z_scores <- scale(data)
  outliers <- abs(z_scores) > 3
  return(outliers)
}

# detect outliers, based on modified z score
detect_modified_outliers <- function(data) {
  median_val <- median(data)
  mad_val <- mad(data)
  modified_z_scores <- (data - median_val) / mad_val
  outliers_modified <- abs(modified_z_scores) > 3.5
  return(outliers_modified)
}





```

``` {r}
# VIC

summary(data_forecastdemand_vic)
summary(data_temperature_vic)
summary(data_demand_vic)

boxplot(data_forecastdemand_vic$FORECASTDEMAND)
boxplot(data_temperature_vic$TEMPERATURE)
boxplot(data_demand_vic$TOTALDEMAND)

hist(data_forecastdemand_vic$FORECASTDEMAND)
hist(data_temperature_vic$TEMPERATURE)
hist(data_demand_vic$TOTALDEMAND)

#data_forecastdemand_vic_z_scores <- scale(data_forecastdemand_vic$FORECASTDEMAND)
#data_forecastdemand_vic_outliers <- abs(data_forecastdemand_vic_z_scores) > 3
#data_forecastdemand_vic_outliers_true <- data_forecastdemand_vic_outliers[data_forecastdemand_vic_outliers == TRUE]
#print(data_forecastdemand_vic_outliers == TRUE)

detect_outliers(data_forecastdemand_vic$FORECASTDEMAND)

```

``` {r}
# SA

```

``` {r}
# QLD

```

``` {r}
# NSW

```

## 4.5 Data Visualisation

``` {r} 
# QLD Data
ggplot(data_demand_qld, aes(x = DATETIME, y = TOTALDEMAND)) +
  geom_point() +
  labs(x = "X-axis label", y = "Y-axis label", title = "Scatter Plot")
```

### NSW 

#### Demand data


```{r}

df_demand_nsw %>% 
  ggplot(aes(x=DATETIME, y=TOTALDEMAND)) +
  geom_line() +
  geom_vline(data = data.frame(x = seq(from = floor_date(min(df_demand_nsw$DATETIME), "year"),
                                       to = ceiling_date(max(df_demand_nsw$DATETIME), "year"),
                                       by = "1 year")), 
             aes(xintercept = as.numeric(x)), 
             linetype = "dotted", color = "red") +
  scale_x_datetime(
    date_breaks = '1 year',
    date_labels = '%Y'
  ) +
  theme_minimal()


```

```{r , message=FALSE}

df_demand_nsw_monthly <- df_demand_nsw %>% 
  group_by(Month, WeekOfMonth, TimeOfDay) %>% 
  summarise(MeanDemand = mean(TOTALDEMAND)) %>% 
  ungroup()

df_demand_nsw_monthly %>% 
  ggplot(aes(x = TimeOfDay, y = MeanDemand)) +
  geom_line(aes(color = WeekOfMonth)) +
  facet_wrap(~ Month, ncol = 3) + 
  scale_x_continuous(name = "Time of Day", breaks = seq(0, 24, by = 3), labels = function(x) sprintf("%02d:00", x)) +
  scale_y_continuous(name = "Mean Total Demand") +
  labs(title = "Weekly Pattern of Electricity Demand by Month") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        strip.text.x = element_text(size = 8))
```

```{r}

df_demand_nsw_seasonly <- df_demand_nsw %>% 
  mutate(Season = case_when(
    Month %in% c(12, 1, 2) ~ "Summer",
    Month %in% c(3, 4, 5) ~ "Autumn",
    Month %in% c(6, 7, 8) ~ "Winter",
    Month %in% c(9, 10, 11) ~ "Spring",
    TRUE ~ NA_character_))

df_demand_nsw_seasonly %>% 
  ggplot(aes(x = factor(Hour), y = TOTALDEMAND)) +
  geom_boxplot(aes(fill=Season)) +
  facet_wrap(~Season, scales = "free_y") + # Faceting by season
  labs(title = "Electricity Demand by Hour Across Seasons",
       x = "Hour of Day",
       y = "Total Demand") +
  scale_x_discrete(name = "Time of Day", breaks = seq(0, 24, by = 2)) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1)) # Improve readability of x axis labels


```

```{r ,message=FALSE}

df_demand_nsw_weekly <- df_demand_nsw %>% 
  group_by(DayOfWeek, TimeOfDay) %>% 
  summarise(MeanDemand = mean(TOTALDEMAND, na.rm = TRUE))

df_demand_nsw_weekly %>% ggplot(aes(x = TimeOfDay, y = MeanDemand)) +
  geom_line(aes(color = DayOfWeek)) +
  scale_x_continuous(name = "Time of Day", breaks = seq(0, 24, by = 1), labels = function(x) sprintf("%02d:00", x)) +
  scale_y_continuous(name = "Mean Total Demand") +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "Mean Total Demand by Time of Day and Day of Week") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

```{r , message=FALSE}

df_demand_nsw_daily <- df_demand_nsw %>%
  group_by(Month, Day) %>% 
  summarise(Avg_daily_demand = mean(TOTALDEMAND)) %>% 
  mutate(DATE = make_date(year=2012, month=Month, day=Day),
         MonthName = month(DATE, label=TRUE))

df_demand_nsw_daily %>% 
  ggplot(aes(x = DATE, y = Avg_daily_demand)) +
  geom_line() + # Draw lines between points
  geom_point() + # Add points for each data point
  geom_smooth() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") + # Customize x-axis labels
  labs(x = "Month", y = "Avg demand", title = "Average daily demand") +
  theme_minimal() # Use a minimal theme


```

Some days are significantly lower demand, suspect to be holidays.



##### Temperature data

```{r}


df_temperature_nsw %>% 
  ggplot(aes(x=DATETIME, y=TEMPERATURE)) +
  geom_line() +
  geom_vline(data = data.frame(x = seq(from = floor_date(min(df_temperature_nsw$DATETIME), "year"),
                                       to = ceiling_date(max(df_temperature_nsw$DATETIME), "year"),
                                       by = "1 year")), 
             aes(xintercept = as.numeric(x)), 
             linetype = "dotted", color = "red") +
  scale_x_datetime(
    date_breaks = '1 year',
    date_labels = '%Y'
  ) +
  theme_minimal()


```

##### Holidays effect

```{r}

## Reference: https://www.michaelplazzer.com/datasets/australian-public-holiday-data/

holidays <- read_csv('../data/Aus_public_hols_2009-2022-1.csv')

holidays_nsw <- holidays %>% 
  filter(State == 'NSW')
```

```{r}

df_demand_nsw_holidays <- df_demand_nsw %>% 
  mutate(Date = date(DATETIME)) %>% 
  mutate(
    IsHoliday = case_when(
      date(DATETIME) %in% holidays_nsw$Date ~ 'Holiday',
      TRUE ~ 'Non-Holiday'
    ))

# Boxplot to compare electricity demand on holidays vs non-holidays
df_demand_nsw_holidays %>% 
  ggplot(aes(x = IsHoliday, y = TOTALDEMAND)) +
  geom_boxplot(aes(fill=IsHoliday)) +
  labs(title = "Electricity Demand on Holidays vs. Non-Holidays",
       x = "", y = "Total Demand") +
  theme_minimal()


```


## ?? Bivariate Analysis

```{r}

df_nsw <- inner_join(df_demand_nsw, df_temperature_nsw, by='DATETIME')

head(df_nsw)

```

```{r}

# Note: Loess regression takes long time to run, gam is faster

df_nsw %>% 
  ggplot(aes(x=TEMPERATURE, y=TOTALDEMAND)) +
  geom_point() +
  geom_smooth(method = 'gam', color = "blue") + # Adds a gam regression line
  labs(title = "Relationship between Temperature and Electricity Demand",
       x = "Temperature",
       y = "Electricity Demand")

```

Correlation testing
```{r}

cor.test(df_nsw$TEMPERATURE, df_nsw$TOTALDEMAND, use = "pearson")

```
p-value is small reject null-hypothesis.

```{r}
## Reference: http://www.bom.gov.au/climate/data/index.shtml
solar_expo_nsw <- read_csv("../data/daily_solar_exposure_bankstown_airport/IDCJAC0016_066137_1800_Data.csv")

```

```{r}

df_solar_expo_nsw <- solar_expo_nsw %>% 
  mutate(
    Year = as.integer(Year), 
    Month = as.integer(Month), 
    Day = as.integer(Day),
    DATE = make_date(Year, Month, Day),
    Solar_exposure = `Daily global solar exposure (MJ/m*m)`
  ) %>% 
  filter(DATE >= as.Date("2010-01-01") & DATE <= as.Date("2021-03-17")) %>% 
  select(DATE, Solar_exposure)

df_solar_expo_nsw %>%
  summarise(na_in_solar_exposure = sum(is.na(Solar_exposure)))

```

1 NA value is found (probably just remove it)

##### Solar Exposures

```{r}
df_solar_expo_nsw <- df_solar_expo_nsw %>% 
  filter(!is.na(Solar_exposure))

df_solar_expo_nsw %>%
  ggplot(aes(DATE, Solar_exposure)) +
  geom_line() +
  geom_vline(data = data.frame(Year = unique(year(df_solar_expo_nsw$DATE))), 
             aes(xintercept = as.Date(paste0(Year, "-01-01"))), 
             linetype = "solid", color = "red") +
  theme_minimal() +
  ggtitle("Solar Exposure Over Time in NSW") +
  xlab("Year") +
  ylab("Solar Exposure")

```



```{r}
# Converts to daily data to match solar exposure data frequency
df_nsw_daily <- df_nsw %>% 
  mutate(DATE = as.Date(DATETIME)) %>% 
  group_by(DATE) %>% 
  summarise(Daily_Avg_Temperature = mean(TEMPERATURE, na.rm = TRUE),
            Daily_Sum_Demand = sum(TOTALDEMAND, na.rm = TRUE))
  
df_nsw_daily <- inner_join(df_nsw_daily, df_solar_expo_nsw, by = 'DATE')
```

```{r}
df_nsw_daily %>% 
  ggplot(aes(Solar_exposure,Daily_Sum_Demand)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Solar Exposure vs Average daily demand NSW") +
  xlab("Solar Exposure") +
  ylab("Average daily demand")

```

```{r}
df_nsw_daily %>% 
  ggplot(aes(Solar_exposure,Daily_Avg_Temperature)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Solar Exposure vs Average daily demand NSW") +
  xlab("Solar Exposure") +
  ylab("Average daily temperature")

```

```{r}
cor.test(df_nsw_daily$Daily_Sum_Demand, df_nsw_daily$Solar_exposure, use = "pearson")

```


```{r}
cor.test(df_nsw_daily$Daily_Avg_Temperature, df_nsw_daily$Solar_exposure, use="pearson")

```
##### Rainfall


```{r}
## Reference: http://www.bom.gov.au/climate/data/index.shtml
rainfall_nsw <- read_csv("../data/daily_rainfall_bankstown_airport/IDCJAC0009_066137_1800_Data.csv")

```

```{r}

df_rainfall_nsw <- rainfall_nsw %>% 
  mutate(
    Year = as.integer(Year), 
    Month = as.integer(Month), 
    Day = as.integer(Day),
    DATE = make_date(Year, Month, Day),
    Rainfall_amount = `Rainfall amount (millimetres)`
  ) %>% 
  filter(DATE >= as.Date("2010-01-01") & DATE <= as.Date("2021-03-17")) %>% 
  select(DATE, Rainfall_amount)
```


```{r}

df_nsw_daily <- inner_join(df_nsw_daily, df_rainfall_nsw, by = 'DATE')

```

```{r}

df_nsw_daily %>% 
  ggplot(aes(Rainfall_amount,Daily_Sum_Demand)) +
  geom_point() +
  geom_smooth()

```

Seems to have no effect on daily sum demand.



slight negative correlation with demand, strong positive correlation with temperature.

##### GDP

```{r , message=FALSE}
## Reference: https://data.worldbank.org/indicator/NY.GDP.MKTP.CD?locations=AU
gdp <- read_csv('../data/GDP.csv', skip=4) %>% filter(`Country Name` == 'Australia')

df_gdp <- gdp %>% 
  pivot_longer(cols=as.character(seq(1960,2022)),
                               names_to = 'Year',
                               values_to = 'GDP') %>% 
  mutate(Year = as.integer(Year)) %>% 
  select(Year, GDP)

```


```{r}
df_gdp %>% ggplot(aes(Year, GDP)) +
  geom_line()

```


```{r}
# Converts to yearly data to match GDP dataset
df_demand_nsw_yearly = df_demand_nsw %>% 
  mutate(Year = year(DATETIME)) %>% 
  group_by(Year) %>% 
  summarise(Avg_yearly_demand = mean(TOTALDEMAND))

df_nsw_yearly <- inner_join(df_demand_nsw_yearly, df_gdp, by = 'Year')
```

```{r}

df_nsw_yearly %>% 
  ggplot(aes(GDP, Avg_yearly_demand)) +
  geom_line() +
  geom_smooth()


```
```{r}

cor.test(df_nsw_yearly$GDP, df_nsw_yearly$Avg_yearly_demand, use="pearson")

```
Not statistically significant. Accept null hypothesis, no correlation.



## ?? Lag-analysis

```{r}

dfts_demand_nsw <- as_tsibble(df_demand_nsw %>% select(DATETIME, TOTALDEMAND), index=DATETIME)


dfts_demand_nsw %>%
  model(STL(TOTALDEMAND ~ season(window = "periodic"))) %>%
  components() %>%
  autoplot()
```
The residual component's structure indicates that after removing the trend and seasonal effects, there are still patterns left to explore, which could be due to other exogenous factors, random noise, or complex dynamics not modeled by simple trend and seasonality. Further investigation needed.



## 4.6 Data Relationships

``` {r}
# generate columns based on elements of time
# demand and forecast time series data format
extract_forecast_datetime_components <- function(data, datetime_column) {
  data %>%
    mutate(
      year = as.numeric(format({{ datetime_column }}, "%Y")),
      month = as.numeric(format({{ datetime_column }}, "%m")),
      day = as.numeric(format({{ datetime_column }}, "%d")),
      hour = as.numeric(format({{ datetime_column }}, "%H")),
      minute = as.numeric(format({{ datetime_column }}, "%M")),
      second = as.numeric(format({{ datetime_column }}, "%S"))
    )
}

# nsw demand time series data format
extract_nsw_demand_datetime_components <- function(data) {
  # Convert DATETIME column to POSIXct
  data$DATETIME <- as.POSIXct(data$DATETIME, format = "%d/%m/%Y %H:%M")
  
  # Extract datetime components
  data$day <- day(data$DATETIME)
  data$month <- month(data$DATETIME)
  data$year <- year(data$DATETIME)
  data$hour <- hour(data$DATETIME)
  data$minute <- minute(data$DATETIME)
  data$second <- second(data$DATETIME)
  
  return(data)
}

# temperate time series data format
extract_temperature_datetime_components <- function(data) {
  # Convert DATETIME column to POSIXct
  data$DATETIME <- as.POSIXct(data$DATETIME, format = "%d/%m/%Y %H:%M")
  
  # Extract datetime components
  data$day <- day(data$DATETIME)
  data$month <- month(data$DATETIME)
  data$year <- year(data$DATETIME)
  data$hour <- hour(data$DATETIME)
  data$minute <- minute(data$DATETIME)
  data$second <- second(data$DATETIME)
  
  return(data)
}

```

``` {r}
# split data time stamps into constituent components
# forecast
new_timestamp_format_data_forecastdemand_vic <- extract_datetime_components(data_forecastdemand_vic, DATETIME)
new_timestamp_format_data_forecastdemand_sa <- extract_datetime_components(data_forecastdemand_sa, DATETIME)
new_timestamp_format_data_forecastdemand_qld <- extract_datetime_components(data_forecastdemand_qld, DATETIME)
new_timestamp_format_data_forecastdemand_nsw <- extract_datetime_components(data_forecastdemand_nsw, DATETIME)

# demand
new_timestamp_format_data_demand_vic <- extract_datetime_components(data_demand_vic, DATETIME)
new_timestamp_format_data_demand_sa <- extract_datetime_components(data_demand_sa, DATETIME)
new_timestamp_format_data_demand_qld <- extract_datetime_components(data_demand_qld, DATETIME)
# need a unique function for nsw
new_timestamp_format_data_demand_nsw <- extract_nsw_demand_datetime_components(data_demand_nsw)

# temperature
new_timestamp_format_data_temperature_vic <- extract_temperature_datetime_components(data_temperature_vic)
new_timestamp_format_data_temperature_sa <- extract_temperature_datetime_components(data_temperature_sa)
new_timestamp_format_data_temperature_qld <- extract_temperature_datetime_components(data_temperature_qld)
new_timestamp_format_data_temperature_nsw <- extract_temperature_datetime_components(data_temperature_nsw)
```

``` {r}
# filter data to the same half hour intervals

generate_subsets <- function(data) {
  # Create an empty list to store results
  subset_list <- list()
  
  # Loop through each hour
  for (hour in 0:23) {
    # Loop through each minute (0 and 30)
    for (minute in c(0, 30)) {
      # Define condition for current hour and minute
      condition <- data$hour == hour & data$minute == minute
      
      # Subset data based on condition
      subset <- data[condition, ]
      
      # Store the result in the list
      subset_list[[paste0(hour, "_", minute)]] <- subset
    }
  }
  
  # Return the list of subsets
  return(subset_list)
}

```

``` {r}

# Call the function with the dataframe
# vic
vic_forecast_subsets <- generate_subsets(new_timestamp_format_data_forecastdemand_vic)
vic_temperature_subsets <- generate_subsets(new_timestamp_format_data_temperature_vic)
vic_demand_subsets <- generate_subsets(new_timestamp_format_data_demand_vic)
#vic_demand_subsets[["5_30"]]

# sa
sa_forecast_subsets <- generate_subsets(new_timestamp_format_data_forecastdemand_sa)
sa_temperature_subsets <- generate_subsets(new_timestamp_format_data_temperature_sa)
sa_demand_subsets <- generate_subsets(new_timestamp_format_data_demand_sa)

# qld
qld_forecast_subsets <- generate_subsets(new_timestamp_format_data_forecastdemand_qld)
qld_temperature_subsets <- generate_subsets(new_timestamp_format_data_temperature_qld)
qld_demand_subsets <- generate_subsets(new_timestamp_format_data_demand_qld)

# nsw
nsw_forecast_subsets <- generate_subsets(new_timestamp_format_data_forecastdemand_nsw)
nsw_temperature_subsets <- generate_subsets(new_timestamp_format_data_temperature_nsw)
nsw_demand_subsets <- generate_subsets(new_timestamp_format_data_demand_nsw)

```

``` {r}

vic_demand_5_30 <- vic_demand_subsets[["5_30"]]
vic_demand_5_30$DATETIME <- as.character(vic_demand_5_30$DATETIME)
vic_temperature_5_30 <- vic_temperature_subsets[["5_30"]]
vic_temperature_5_30$DATETIME <- as.character(vic_temperature_5_30$DATETIME)

```

## 4.7 Outlier Detection

## 4.8 Feature Detecting

## 4.9 Findings

---

# 5.0 Analysis of Results

---

# 6.0 Discussion

---

# 7.0 Conclusions and Recommendations

---

# Reference List

---

# Appendix

